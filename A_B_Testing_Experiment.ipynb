{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTpxHefOQ9RzgZdoJxRIvM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IIIaryanIII/A-B-Testing-Experiment/blob/main/A_B_Testing_Experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RppL6hyt4rIU",
        "outputId": "56f90714-5f2d-4408-f3ec-1203a64fde3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas numpy scipy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import zipfile\n",
        "\n",
        "print(\"Loading dataset...\")\n",
        "\n",
        "# Unzip the file first if it's zipped\n",
        "zip_file_path = \"ab_data.csv.zip\"\n",
        "csv_file_name = \"ab_data.csv\"\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\") # Extract to the current directory\n",
        "\n",
        "df = pd.read_csv(csv_file_name)\n",
        "\n",
        "\n",
        "print(df.head())\n",
        "print(\"\\nData Summary:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Corrected group filtering based on actual column values\n",
        "groupA = df[df['group'] == 'control']\n",
        "groupB = df[df['group'] == 'treatment']\n",
        "\n",
        "convA = groupA['converted'].mean()\n",
        "convB = groupB['converted'].mean()\n",
        "\n",
        "print(\"\\nConversion Rate A:\", round(convA, 4))\n",
        "print(\"Conversion Rate B:\", round(convB, 4))\n",
        "\n",
        "successA = groupA['converted'].sum()\n",
        "failA = len(groupA) - successA\n",
        "\n",
        "save_failA_if_zero = max(1, failA)\n",
        "save_failB_if_zero = max(1, failB)\n",
        "\n",
        "successB = groupB['converted'].sum()\n",
        "failB = len(groupB) - successB\n",
        "\n",
        "contingency_table = np.array([[successA, save_failA_if_zero],\n",
        "                              [successB, save_failB_if_zero]])\n",
        "\n",
        "chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "print(\"\\nChi-square test results:\")\n",
        "print(\"Chi2 value:\", chi2)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "\n",
        "lift = (convB - convA) / convA * 100\n",
        "print(\"\\nLift of Variant B over A:\", round(lift, 2), \"%\")\n",
        "\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "print(\"\\nFINAL RECOMMENDATION:\")\n",
        "if p_value < alpha and convB > convA:\n",
        "    print(\" Version B is statistically significantly better. Recommend rollout.\")\n",
        "elif p_value < alpha and convA > convB:\n",
        "    print(\" Version A performs better. Keep A as control.\")\n",
        "else:\n",
        "    print(\" No statistically significant difference. Keep running the experiment or collect more data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJD61VH94wVO",
        "outputId": "12caea03-ab78-4fe4-d013-4bde6df7ece4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "   user_id                   timestamp      group landing_page  converted\n",
            "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
            "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
            "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
            "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
            "4   864975  2017-01-21 01:52:26.210827    control     old_page          1\n",
            "\n",
            "Data Summary:\n",
            "             user_id      converted\n",
            "count  294478.000000  294478.000000\n",
            "mean   787974.124733       0.119659\n",
            "std     91210.823776       0.324563\n",
            "min    630000.000000       0.000000\n",
            "25%    709032.250000       0.000000\n",
            "50%    787933.500000       0.000000\n",
            "75%    866911.750000       0.000000\n",
            "max    945999.000000       1.000000\n",
            "\n",
            "Conversion Rate A: 0.1204\n",
            "Conversion Rate B: 0.1189\n",
            "\n",
            "Chi-square test results:\n",
            "Chi2 value: 1.5159618356336584\n",
            "p-value: 0.2182316121631168\n",
            "\n",
            "Lift of Variant B over A: -1.23 %\n",
            "\n",
            "FINAL RECOMMENDATION:\n",
            " No statistically significant difference. Keep running the experiment or collect more data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import zipfile\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# ---------- USER CONFIG ----------\n",
        "ZIP_PATH = \"ab_data.csv.zip\"   # or set to None if not zipped\n",
        "CSV_NAME = \"ab_data.csv\"\n",
        "GROUP_COL = \"group\"            # adjust if your dataset uses 'variant' or 'bucket'\n",
        "CONV_COL = \"converted\"         # adjust if your dataset uses 'is_converted' etc.\n",
        "CONTROL_LABEL = \"control\"      # or \"A\"\n",
        "TREATMENT_LABEL = \"treatment\"  # or \"B\"\n",
        "ALPHA = 0.05\n",
        "# ---------------------------------\n",
        "\n",
        "def load_csv(zip_path, csv_name):\n",
        "    if zip_path and os.path.exists(zip_path):\n",
        "        print(f\"Unzipping {zip_path} ...\")\n",
        "        with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "            # If csv_name not in zip, extract everything and try to find csv\n",
        "            if csv_name in z.namelist():\n",
        "                z.extract(csv_name, \".\")\n",
        "                return pd.read_csv(csv_name)\n",
        "            else:\n",
        "                z.extractall(\".\")\n",
        "                # try to find first csv\n",
        "                for name in z.namelist():\n",
        "                    if name.lower().endswith(\".csv\"):\n",
        "                        print(f\"Using extracted file: {name}\")\n",
        "                        return pd.read_csv(name)\n",
        "                raise FileNotFoundError(\"No CSV found inside the zip.\")\n",
        "    elif os.path.exists(csv_name):\n",
        "        return pd.read_csv(csv_name)\n",
        "    else:\n",
        "        raise FileNotFoundError(\"Neither zip nor CSV found. Check paths.\")\n",
        "\n",
        "def safe_int(x):\n",
        "    try:\n",
        "        return int(x)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def main():\n",
        "    print(\"Loading dataset...\")\n",
        "    try:\n",
        "        df = load_csv(ZIP_PATH, CSV_NAME)\n",
        "    except Exception as e:\n",
        "        print(\"ERROR loading data:\", e)\n",
        "        sys.exit(1)\n",
        "\n",
        "    print(df.head())\n",
        "    print(\"\\nData Summary:\")\n",
        "    print(df.describe(include=\"all\"))\n",
        "\n",
        "    # Basic checks\n",
        "    if GROUP_COL not in df.columns or CONV_COL not in df.columns:\n",
        "        print(f\"Required columns not found. Expected '{GROUP_COL}' and '{CONV_COL}' in CSV.\")\n",
        "        print(\"Columns available:\", df.columns.tolist())\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Clean/ensure conversion column is 0/1\n",
        "    df[CONV_COL] = df[CONV_COL].apply(safe_int)\n",
        "    df = df.dropna(subset=[GROUP_COL, CONV_COL])\n",
        "\n",
        "    # Filter groups robustly (case-insensitive)\n",
        "    df[GROUP_COL] = df[GROUP_COL].astype(str).str.lower()\n",
        "    control_label = CONTROL_LABEL.lower()\n",
        "    treatment_label = TREATMENT_LABEL.lower()\n",
        "\n",
        "    if control_label not in df[GROUP_COL].unique() or treatment_label not in df[GROUP_COL].unique():\n",
        "        print(\"Warning: specified group labels not found. Available groups:\", df[GROUP_COL].unique())\n",
        "        # try to auto-detect two groups\n",
        "        uniques = df[GROUP_COL].unique()\n",
        "        if len(uniques) >= 2:\n",
        "            control_label, treatment_label = uniques[0], uniques[1]\n",
        "            print(f\"Auto-using control='{control_label}', treatment='{treatment_label}'\")\n",
        "        else:\n",
        "            print(\"Not enough distinct groups to run A/B test.\")\n",
        "            sys.exit(1)\n",
        "\n",
        "    groupA = df[df[GROUP_COL] == control_label]\n",
        "    groupB = df[df[GROUP_COL] == treatment_label]\n",
        "\n",
        "    nA = len(groupA)\n",
        "    nB = len(groupB)\n",
        "    successA = int(groupA[CONV_COL].sum())\n",
        "    successB = int(groupB[CONV_COL].sum())\n",
        "    failA = nA - successA\n",
        "    failB = nB - successB\n",
        "\n",
        "    convA = successA / nA if nA > 0 else 0.0\n",
        "    convB = successB / nB if nB > 0 else 0.0\n",
        "\n",
        "    print(f\"\\nCounts: nA={nA}, successA={successA}, failA={failA}\")\n",
        "    print(f\"        nB={nB}, successB={successB}, failB={failB}\")\n",
        "    print(f\"\\nConversion Rate A (control): {convA:.4f}\")\n",
        "    print(f\"Conversion Rate B (treatment): {convB:.4f}\")\n",
        "\n",
        "    # Contingency table\n",
        "    table = np.array([[successA, failA],\n",
        "                      [successB, failB]])\n",
        "    print(\"\\nContingency table:\\n\", table)\n",
        "\n",
        "    # Choose test: if expected freq < 5 anywhere -> use Fisher's exact test\n",
        "    chi2, p_chi2, dof, expected = stats.chi2_contingency(table)\n",
        "    print(\"\\nExpected frequencies (from chi2):\\n\", expected)\n",
        "    if (expected < 5).any() or (table == 0).any():\n",
        "        print(\"\\nUsing Fisher's exact test (small counts or zero cell detected).\")\n",
        "        # fisher_exact expects a 2x2 table of integers\n",
        "        try:\n",
        "            oddsratio, p_value = stats.fisher_exact(table)\n",
        "            test_used = \"fisher_exact\"\n",
        "        except Exception as e:\n",
        "            print(\"Fisher failed:\", e)\n",
        "            p_value = p_chi2\n",
        "            test_used = \"chi2_fallback\"\n",
        "    else:\n",
        "        p_value = p_chi2\n",
        "        test_used = \"chi2\"\n",
        "\n",
        "    # Lift (handle convA == 0)\n",
        "    if convA == 0:\n",
        "        lift = float('inf') if convB > 0 else 0.0\n",
        "    else:\n",
        "        lift = (convB - convA) / convA * 100\n",
        "\n",
        "    print(f\"\\nTest used: {test_used}\")\n",
        "    print(f\"Chi2 stat (if computed): {chi2:.4f}\")\n",
        "    print(f\"p-value: {p_value:.6f}\")\n",
        "    if np.isfinite(lift):\n",
        "        print(f\"\\nLift of Variant B over A: {lift:.2f} %\")\n",
        "    else:\n",
        "        print(\"\\nLift of Variant B over A: infinite (control conv=0)\")\n",
        "\n",
        "    # Recommendation (two-sided p-value + direction)\n",
        "    if p_value < ALPHA:\n",
        "        if convB > convA:\n",
        "            print(\"\\n Recommendation: Treatment (B) is significantly better than Control (A). Consider rolling out B.\")\n",
        "        else:\n",
        "            print(\"\\n Recommendation: Control (A) is significantly better than Treatment (B). Keep A.\")\n",
        "    else:\n",
        "        print(\"\\n Recommendation: No statistically significant difference (p >= {}). Collect more data or run longer.\".format(ALPHA))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6vav18O5NSm",
        "outputId": "a08845c1-992d-42ad-97e1-893560bcc3d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Unzipping ab_data.csv.zip ...\n",
            "   user_id                   timestamp      group landing_page  converted\n",
            "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
            "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
            "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
            "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
            "4   864975  2017-01-21 01:52:26.210827    control     old_page          1\n",
            "\n",
            "Data Summary:\n",
            "              user_id                   timestamp      group landing_page  \\\n",
            "count   294478.000000                      294478     294478       294478   \n",
            "unique            NaN                      294478          2            2   \n",
            "top               NaN  2017-01-16 12:40:24.467417  treatment     old_page   \n",
            "freq              NaN                           1     147276       147239   \n",
            "mean    787974.124733                         NaN        NaN          NaN   \n",
            "std      91210.823776                         NaN        NaN          NaN   \n",
            "min     630000.000000                         NaN        NaN          NaN   \n",
            "25%     709032.250000                         NaN        NaN          NaN   \n",
            "50%     787933.500000                         NaN        NaN          NaN   \n",
            "75%     866911.750000                         NaN        NaN          NaN   \n",
            "max     945999.000000                         NaN        NaN          NaN   \n",
            "\n",
            "            converted  \n",
            "count   294478.000000  \n",
            "unique            NaN  \n",
            "top               NaN  \n",
            "freq              NaN  \n",
            "mean         0.119659  \n",
            "std          0.324563  \n",
            "min          0.000000  \n",
            "25%          0.000000  \n",
            "50%          0.000000  \n",
            "75%          0.000000  \n",
            "max          1.000000  \n",
            "\n",
            "Counts: nA=147202, successA=17723, failA=129479\n",
            "        nB=147276, successB=17514, failB=129762\n",
            "\n",
            "Conversion Rate A (control): 0.1204\n",
            "Conversion Rate B (treatment): 0.1189\n",
            "\n",
            "Contingency table:\n",
            " [[ 17723 129479]\n",
            " [ 17514 129762]]\n",
            "\n",
            "Expected frequencies (from chi2):\n",
            " [[ 17614.07260984 129587.92739016]\n",
            " [ 17622.92739016 129653.07260984]]\n",
            "\n",
            "Test used: chi2\n",
            "Chi2 stat (if computed): 1.5160\n",
            "p-value: 0.218232\n",
            "\n",
            "Lift of Variant B over A: -1.23 %\n",
            "\n",
            " Recommendation: No statistically significant difference (p >= 0.05). Collect more data or run longer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QTkSocYY6vDy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}